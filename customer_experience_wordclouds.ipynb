{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from datetime import datetime\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import re\n",
    "\n",
    "# Download NLTK data if needed\n",
    "# nltk.download()\n",
    "\n",
    "# Initialize French language model and stopwords\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "nlp.max_length = 50000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and process data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crm_cols = [\"DATE_CONTACT\", \"CODIF_NIVEAU_1\", \"CODIF_NIVEAU_2\", \"COMMENTAIRES_AGENT\"]\n",
    "crm = pd.read_csv(\n",
    "    \"./datas/V_CODIF_CRM.txt\", on_bad_lines=\"skip\", sep=\"\\t\", usecols=crm_cols\n",
    ")\n",
    "\n",
    "# Convert columns into the right format\n",
    "crm[\"DATE_CONTACT\"] = pd.to_datetime(crm[\"DATE_CONTACT\"])\n",
    "crm[\"year_month\"] = crm[\"DATE_CONTACT\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "crm.sort_values(by=[\"DATE_CONTACT\"], inplace=True)\n",
    "crm.reset_index(inplace=True)\n",
    "\n",
    "# Normalization and processing of comments\n",
    "crm[\"COMMENTAIRES_AGENT\"] = crm[\"COMMENTAIRES_AGENT\"].apply(unidecode)\n",
    "crm[\"COMMENTAIRES_AGENT\"] = crm[\"COMMENTAIRES_AGENT\"].str.lower()\n",
    "\n",
    "# Remove STOP words\n",
    "stopwords_worldbrain = pd.read_csv(\n",
    "    \"./words_lists/STOP_WORDS_WordlBrain_updated.txt\", header=None\n",
    ")\n",
    "stopwords_worldbrain = stopwords_worldbrain[0].tolist()\n",
    "crm[\"COMMENTAIRES_processed\"] = crm[\"COMMENTAIRES_AGENT\"].apply(\n",
    "    lambda x: \" \".join(\n",
    "        [\n",
    "            word\n",
    "            for word in x.split()\n",
    "            if word.lower() and word not in stopwords_worldbrain\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Remove COMMON words\n",
    "remove_words = (\n",
    "    pd.read_csv(\"./words_lists/remove_words.csv\").dropna()[\"word_to_remove\"].tolist()\n",
    ")\n",
    "full_words_remove = stopwords_worldbrain + remove_words\n",
    "\n",
    "# Convert columns into the right format\n",
    "crm[\n",
    "    [\"CODIF_NIVEAU_1\", \"CODIF_NIVEAU_2\", \"COMMENTAIRES_AGENT\", \"COMMENTAIRES_processed\"]\n",
    "] = crm[\n",
    "    [\"CODIF_NIVEAU_1\", \"CODIF_NIVEAU_2\", \"COMMENTAIRES_AGENT\", \"COMMENTAIRES_processed\"]\n",
    "].astype(\n",
    "    str\n",
    ")\n",
    "crm[\"DATE_CONTACT\"] = pd.to_datetime(crm[\"DATE_CONTACT\"])\n",
    "crm[\"year_month\"] = pd.to_datetime(crm[\"year_month\"])\n",
    "\n",
    "# Export processed data to CSV (if needed)\n",
    "# crm.to_csv(\"./datas/datas_processed.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import processed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crm = pd.read_csv(\".\\datas\\datas_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Wordclouds: raw datas vs. processed datas (period of 6 months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2022, 4, 25).strftime(\"%Y-%m-%d\")\n",
    "end_date = datetime(2022, 10, 25).strftime(\"%Y-%m-%d\")\n",
    "mask = (crm[\"DATE_CONTACT\"] > start_date) & (crm[\"DATE_CONTACT\"] <= end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crm_raw = crm.loc[mask]\n",
    "column_str_raw = crm_raw[\"COMMENTAIRES_AGENT\"].str.cat(sep=\", \")\n",
    "column_str_raw = nltk.word_tokenize(column_str_raw)\n",
    "column_str_raw = [t.lower() for t in column_str_raw if t not in string.punctuation]\n",
    "column_str_raw = \", \".join(column_str_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process datas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crm_preprocessed = crm.loc[mask]\n",
    "column_str_process = crm_preprocessed[\"COMMENTAIRES_processed\"].str.cat(sep=\", \")\n",
    "column_str_process = nltk.word_tokenize(column_str_process)\n",
    "column_str_process = [\n",
    "    t.lower() for t in column_str_process if t not in string.punctuation\n",
    "]\n",
    "column_str_process = [\n",
    "    word for word in column_str_process if word not in full_words_remove\n",
    "]\n",
    "column_str_process = [unidecode(x) for x in column_str_process]\n",
    "column_str_process = \", \".join(column_str_process)\n",
    "\n",
    "# Lemmatization\n",
    "lemmas_process = [t.lemma_ for t in nlp(column_str_process)]\n",
    "lemmas_process = \", \".join(lemmas_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot raw vs. processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "axes[0].imshow(\n",
    "    WordCloud(\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        background_color=\"white\",\n",
    "        colormap=\"viridis\",\n",
    "        max_words=100,\n",
    "        random_state=30,\n",
    "    ).generate(column_str_raw)\n",
    ")\n",
    "axes[0].set_title(\"RAW\", fontsize=18, pad=10)\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(\n",
    "    WordCloud(\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        background_color=\"white\",\n",
    "        stopwords=stopwords_worldbrain,\n",
    "        colormap=\"viridis\",\n",
    "        max_words=100,\n",
    "        random_state=30,\n",
    "    ).generate(lemmas_process)\n",
    ")\n",
    "axes[1].set_title(\"Stopwords, Lemmatized and Common words\", fontsize=18, pad=10)\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codif Niveau 1 (full period)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crm_codif1 = crm.copy()\n",
    "crm_alerting = crm_codif1[crm_codif1[\"CODIF_NIVEAU_1\"] == \"BoÃ®tier Alerting\"]\n",
    "column_str_alerting = crm_alerting[\"COMMENTAIRES_AGENT\"].str.cat(sep=\", \")\n",
    "column_str_alerting = nltk.word_tokenize(column_str_alerting)\n",
    "column_str_alerting = [\n",
    "    t.lower() for t in column_str_alerting if t not in string.punctuation\n",
    "]\n",
    "column_str_alerting = [\n",
    "    word for word in column_str_alerting if word not in full_words_remove\n",
    "]\n",
    "column_str_alerting = [unidecode(x) for x in column_str_alerting]\n",
    "column_str_alerting = \", \".join(column_str_alerting)\n",
    "lemmas_alerting = [t.lemma_ for t in nlp(column_str_alerting)]\n",
    "lemmas_alerting = \", \".join(lemmas_alerting)\n",
    "\n",
    "crm_secure = crm_codif1[crm_codif1[\"CODIF_NIVEAU_1\"] == \"Coyote Secure\"]\n",
    "column_str_secure = crm_secure[\"COMMENTAIRES_AGENT\"].str.cat(sep=\", \")\n",
    "column_str_secure = nltk.word_tokenize(column_str_secure)\n",
    "column_str_secure = [\n",
    "    t.lower() for t in column_str_secure if t not in string.punctuation\n",
    "]\n",
    "column_str_secure = [\n",
    "    word for word in column_str_secure if word not in full_words_remove\n",
    "]\n",
    "column_str_secure = [unidecode(x) for x in column_str_secure]\n",
    "column_str_secure = \", \".join(column_str_secure)\n",
    "lemmas_secure = [t.lemma_ for t in nlp(column_str_secure)]\n",
    "lemmas_secure = \", \".join(lemmas_secure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot codif1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "axes[0].imshow(\n",
    "    WordCloud(\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        background_color=\"white\",\n",
    "        stopwords=full_words_remove,\n",
    "        colormap=\"viridis\",\n",
    "        max_words=100,\n",
    "        random_state=30,\n",
    "        collocations=False,\n",
    "    ).generate(lemmas_alerting)\n",
    ")\n",
    "axes[0].set_title(\"Alerting\", fontsize=18, pad=10)\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(\n",
    "    WordCloud(\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        background_color=\"white\",\n",
    "        stopwords=full_words_remove,\n",
    "        colormap=\"viridis\",\n",
    "        max_words=100,\n",
    "        random_state=30,\n",
    "        collocations=False,\n",
    "    ).generate(lemmas_secure)\n",
    ")\n",
    "axes[1].set_title(\"Secure\", fontsize=18, pad=10)\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codif Niveau 2 (period of 1 year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crm_codif2 = crm.copy()\n",
    "\n",
    "codif2 = [\n",
    "    \"FACTURATION\",\n",
    "    \"VENTE\",\n",
    "    \"FidÃ©lisation\",\n",
    "    \"ASSISTANCE TECHNIQUE (TELEDEPANNAGE)\",\n",
    "    \"GESTION DE COMPTE\",\n",
    "    \"RESILIATION\",\n",
    "    \"AUTRE\",\n",
    "]\n",
    "\n",
    "crm_codif2.loc[~crm_codif2[\"CODIF_NIVEAU_2\"].isin(codif2), \"CODIF_NIVEAU_2\"] = \"AUTRE\"\n",
    "\n",
    "codif2 = [\n",
    "    x.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"Ã©\", \"e\")\n",
    "    for x in codif2\n",
    "]\n",
    "\n",
    "crm_codif2[\"CODIF_NIVEAU_2\"] = crm_codif2[\"CODIF_NIVEAU_2\"].apply(\n",
    "    lambda x: x.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"Ã©\", \"e\")\n",
    ")\n",
    "\n",
    "start_date = datetime(2021, 10, 25).strftime(\"%Y-%m-%d\")\n",
    "end_date = datetime(2022, 10, 25).strftime(\"%Y-%m-%d\")\n",
    "mask = (crm[\"DATE_CONTACT\"] > start_date) & (crm[\"DATE_CONTACT\"] <= end_date)\n",
    "crm_codif2 = crm_codif2.loc[mask]\n",
    "\n",
    "for x in codif2:\n",
    "    vars()[f\"df_{x}\"] = crm_codif2[\"comms_sw\"][(crm_codif2[\"CODIF_NIVEAU_2\"] == x)]\n",
    "    vars()[f\"str_{x}\"] = vars()[f\"df_{x}\"].str.cat(sep=\", \")\n",
    "    vars()[f\"str_{x}\"] = unidecode(vars()[f\"str_{x}\"])\n",
    "    vars()[f\"words_{x}\"] = word_tokenize(\n",
    "        vars()[f\"str_{x}\"], preserve_line=True, language=\"french\"\n",
    "    )\n",
    "    vars()[f\"words_no_punct_{x}\"] = [\n",
    "        word.lower() for word in vars()[f\"words_{x}\"] if word.isalpha()\n",
    "    ]\n",
    "    vars()[f\"clean_words_{x}\"] = [\n",
    "        i for i in vars()[f\"words_no_punct_{x}\"] if i not in full_words_remove\n",
    "    ]\n",
    "    vars()[f\"lemm_words_{x}\"] = [\n",
    "        WordNetLemmatizer().lemmatize(word) for word in vars()[f\"clean_words_{x}\"]\n",
    "    ]\n",
    "    vars()[f\"lemm_words_{x}\"] = \", \".join(vars()[f\"lemm_words_{x}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot codif2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(codif2), 1, figsize=(15, 40))\n",
    "count = 0\n",
    "\n",
    "for x in codif2:\n",
    "    count += 1\n",
    "    axes[count - 1].imshow(\n",
    "        WordCloud(\n",
    "            width=1000,\n",
    "            height=500,\n",
    "            background_color=\"white\",\n",
    "            stopwords=remove_words,\n",
    "            collocations=False,\n",
    "            colormap=\"viridis\",\n",
    "            max_words=100,\n",
    "            random_state=30,\n",
    "        ).generate(vars()[f\"lemm_words_{x}\"])\n",
    "    )\n",
    "    axes[count - 1].set_title(f\"{x}\", fontsize=18, pad=5)\n",
    "    axes[count - 1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordCloud monthly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_months = [\n",
    "    \"2021-02\",\n",
    "    \"2021-03\",\n",
    "    \"2021-04\",\n",
    "    \"2021-05\",\n",
    "    \"2021-06\",\n",
    "    \"2021-07\",\n",
    "    \"2021-08\",\n",
    "    \"2021-09\",\n",
    "    \"2021-10\",\n",
    "    \"2021-11\",\n",
    "    \"2021-12\",\n",
    "    \"2022-01\",\n",
    "    \"2022-02\",\n",
    "    \"2022-03\",\n",
    "    \"2022-04\",\n",
    "    \"2022-05\",\n",
    "    \"2022-06\",\n",
    "    \"2022-07\",\n",
    "    \"2022-08\",\n",
    "    \"2022-09\",\n",
    "    \"2022-10\",\n",
    "]\n",
    "\n",
    "stopwords_worldbrain = pd.read_csv(\n",
    "    \"./my_words_lists/STOP_WORDS_WordlBrain_updated.txt\", header=None\n",
    ")\n",
    "stopwords_worldbrain = stopwords_worldbrain[0].tolist()\n",
    "crm[\"commentaires_stopwords\"] = crm[\"COMMENTAIRES_AGENT\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in stopwords_worldbrain])\n",
    ")\n",
    "\n",
    "remove_words = (\n",
    "    pd.read_csv(\"./my_words_lists/remove_words.csv\").dropna()[\"word\"].tolist()\n",
    ")\n",
    "crm[\"commentaires_stopwords\"] = crm[\"commentaires_stopwords\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in remove_words])\n",
    ")\n",
    "crm[\"commentaires_stopwords\"] = crm[\"commentaires_stopwords\"].apply(unidecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(list_months), figsize=(120, 6))\n",
    "plt.suptitle(\"WordClouds monthly\", fontsize=24)\n",
    "count = 0\n",
    "\n",
    "for text in list_months:\n",
    "    vars()[text] = crm[\"commentaires_stopwords\"][(crm[\"year_month\"] == text)]\n",
    "    vars()[text] = [text.strip() for text in vars()[text]]\n",
    "    vars()[text] = \" \".join(vars()[text])\n",
    "    vars()[text] = re.sub(\n",
    "        r\"[!\\\"#$%&()*+,-./:;<=>?@[\\\\\\]^_`{|}~]+\", \" \", vars()[text]\n",
    "    ).lower()\n",
    "    vars()[text] = nlp(vars()[text][:])\n",
    "    vars()[text] = [token.lemma_ for token in vars()[text]]\n",
    "    vars()[text] = \" \".join(vars()[text])\n",
    "\n",
    "    count += 1\n",
    "    axes[count - 1].imshow(\n",
    "        WordCloud(\n",
    "            width=1000,\n",
    "            height=500,\n",
    "            background_color=\"white\",\n",
    "            stopwords=stopwords_worldbrain,\n",
    "            colormap=\"viridis\",\n",
    "            max_words=100,\n",
    "            random_state=30,\n",
    "        ).generate(vars()[text])\n",
    "    )\n",
    "    axes[count - 1].set_title(f\"{text}\", fontsize=18, pad=5)\n",
    "    axes[count - 1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract words frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict()\n",
    "\n",
    "for word in lemm_words:\n",
    "    if word in counts:\n",
    "        counts[word] += 1\n",
    "    else:\n",
    "        counts[word] = 1\n",
    "\n",
    "counts = {key: val for key, val in counts.items() if val > 10}\n",
    "\n",
    "with open(f\"./words_count.csv\", \"w\", errors=\"ignore\") as f:\n",
    "    for key in counts.keys():\n",
    "        f.write(\"%s, %s\\n\" % (key, counts[key]))\n",
    "\n",
    "counting = crm[\"commentaires_stopwords\"]\n",
    "counting = [text.strip() for text in counting]\n",
    "counting = \" \".join(counting)\n",
    "counting = re.sub(r\"[!\\\"#$%&()*+,-./:;<=>?@[\\\\\\]^_`{|}~]+\", \" \", counting).lower()\n",
    "\n",
    "# Frequency of each word in string\n",
    "counts = dict()\n",
    "words = str.split(counting)\n",
    "for word in words:\n",
    "    if word in counts:\n",
    "        counts[word] += 1\n",
    "    else:\n",
    "        counts[word] = 1\n",
    "\n",
    "# Clean my dict of counting\n",
    "counts = {key: val for key, val in counts.items() if val > 10}\n",
    "\n",
    "# Convert dictionary into a CSV\n",
    "with open(f\"./words_lists/words_count.csv\", \"w\", errors=\"ignore\") as f:\n",
    "    for key in counts.keys():\n",
    "        f.write(\"%s, %s\\n\" % (key, counts[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
